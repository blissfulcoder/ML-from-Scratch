{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense,Activation, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "41995       0    ...            0         0         0         0         0   \n",
       "41996       0    ...            0         0         0         0         0   \n",
       "41997       0    ...            0         0         0         0         0   \n",
       "41998       0    ...            0         0         0         0         0   \n",
       "41999       0    ...            0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv(\"d:/ML--perceptron/mnist/train.csv\")\n",
    "ds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11000, 785)\n"
     ]
    }
   ],
   "source": [
    "data=ds.values[6000:17000]\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11000, 784)\n",
      "(11000,)\n"
     ]
    }
   ],
   "source": [
    "#X = data[:,1:]\n",
    "X = data[:,1:]/255.0\n",
    "y=data[:,0]\n",
    "print (X.shape)\n",
    "print (y.shape)\n",
    "nb_classes=len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "6 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "2 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "6 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "Y = np_utils.to_categorical(y)\n",
    "for ix in range(10):\n",
    "    print (y[ix], Y[ix])\n",
    "##with sigmoid dont need this encoding but with softmax it's required.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8800, 784) (8800, 10)\n"
     ]
    }
   ],
   "source": [
    "split = int(0.8*data.shape[0])\n",
    "X_train=X[:split]\n",
    "X_test=X[split:]\n",
    "y_train=Y[:split]\n",
    "y_test = Y[split:]\n",
    "print (X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output is bounded in 0 to 255 so we will use relu.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#softmax goes in hand in hand with categorical crossentropy..\n",
    "#backpropogation required when writing own loss function..\n",
    "#optimizer works inside loss fn, and controls how to come down the slope.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8800 samples, validate on 2200 samples\n",
      "Epoch 1/20\n",
      "8800/8800 [==============================] - 4s 403us/step - loss: 0.5905 - acc: 0.8244 - val_loss: 0.2931 - val_acc: 0.9191\n",
      "Epoch 2/20\n",
      "8800/8800 [==============================] - 3s 290us/step - loss: 0.2903 - acc: 0.9117 - val_loss: 0.2276 - val_acc: 0.9368\n",
      "Epoch 3/20\n",
      "8800/8800 [==============================] - 3s 312us/step - loss: 0.2176 - acc: 0.9344 - val_loss: 0.1916 - val_acc: 0.9486\n",
      "Epoch 4/20\n",
      "8800/8800 [==============================] - 3s 304us/step - loss: 0.1675 - acc: 0.9511 - val_loss: 0.1784 - val_acc: 0.9505\n",
      "Epoch 5/20\n",
      "8800/8800 [==============================] - 3s 337us/step - loss: 0.1433 - acc: 0.9557 - val_loss: 0.1578 - val_acc: 0.9536\n",
      "Epoch 6/20\n",
      "8800/8800 [==============================] - 3s 324us/step - loss: 0.1214 - acc: 0.9638 - val_loss: 0.1537 - val_acc: 0.9550\n",
      "Epoch 7/20\n",
      "8800/8800 [==============================] - 3s 350us/step - loss: 0.0997 - acc: 0.9703 - val_loss: 0.1360 - val_acc: 0.9586\n",
      "Epoch 8/20\n",
      "8800/8800 [==============================] - 3s 343us/step - loss: 0.0876 - acc: 0.9728 - val_loss: 0.1361 - val_acc: 0.9568\n",
      "Epoch 9/20\n",
      "8800/8800 [==============================] - 3s 335us/step - loss: 0.0775 - acc: 0.9769 - val_loss: 0.1329 - val_acc: 0.9591\n",
      "Epoch 10/20\n",
      "8800/8800 [==============================] - 3s 347us/step - loss: 0.0642 - acc: 0.9814 - val_loss: 0.1237 - val_acc: 0.9595\n",
      "Epoch 11/20\n",
      "8800/8800 [==============================] - 3s 354us/step - loss: 0.0556 - acc: 0.9836 - val_loss: 0.1247 - val_acc: 0.9577\n",
      "Epoch 12/20\n",
      "8800/8800 [==============================] - 3s 339us/step - loss: 0.0489 - acc: 0.9835 - val_loss: 0.1245 - val_acc: 0.9595\n",
      "Epoch 13/20\n",
      "8800/8800 [==============================] - 3s 340us/step - loss: 0.0446 - acc: 0.9870 - val_loss: 0.1323 - val_acc: 0.9595\n",
      "Epoch 14/20\n",
      "8800/8800 [==============================] - 3s 333us/step - loss: 0.0369 - acc: 0.9895 - val_loss: 0.1307 - val_acc: 0.9618\n",
      "Epoch 15/20\n",
      "8800/8800 [==============================] - 3s 327us/step - loss: 0.0349 - acc: 0.9895 - val_loss: 0.1355 - val_acc: 0.9623\n",
      "Epoch 16/20\n",
      "8800/8800 [==============================] - 3s 332us/step - loss: 0.0362 - acc: 0.9880 - val_loss: 0.1259 - val_acc: 0.9605\n",
      "Epoch 17/20\n",
      "8800/8800 [==============================] - 3s 321us/step - loss: 0.0319 - acc: 0.9916 - val_loss: 0.1303 - val_acc: 0.9650\n",
      "Epoch 18/20\n",
      "8800/8800 [==============================] - 3s 332us/step - loss: 0.0292 - acc: 0.9914 - val_loss: 0.1298 - val_acc: 0.9632\n",
      "Epoch 19/20\n",
      "8800/8800 [==============================] - 3s 344us/step - loss: 0.0251 - acc: 0.9917 - val_loss: 0.1398 - val_acc: 0.9618\n",
      "Epoch 20/20\n",
      "8800/8800 [==============================] - 3s 336us/step - loss: 0.0259 - acc: 0.9923 - val_loss: 0.1295 - val_acc: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23e32a6beb8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, nb_epoch=20, batch_size=50, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight -> absolute updation and not relative updation hence normalization\n",
    "#is required.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x0000023E32DB7400>\n",
      "(784, 512)\n",
      "(512,)\n",
      "dense_1\n",
      "--------------------\n",
      "<keras.layers.core.Activation object at 0x0000023E26AA55C0>\n",
      "activation_1\n",
      "--------------------\n",
      "<keras.layers.core.Dropout object at 0x0000023E323E6F60>\n",
      "dropout_1\n",
      "--------------------\n",
      "<keras.layers.core.Dense object at 0x0000023E32DB7A58>\n",
      "(512, 10)\n",
      "(10,)\n",
      "dense_2\n",
      "--------------------\n",
      "<keras.layers.core.Activation object at 0x0000023E32DB7588>\n",
      "activation_2\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "##to get value of weights for specific values..\n",
    "for layer in model.layers:\n",
    "    print (layer)\n",
    "    if len(layer.get_weights())>0:\n",
    "        print (layer.get_weights()[0].shape)\n",
    "        print (layer.get_weights()[1].shape)\n",
    "    print (layer.get_config()['name'])\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
