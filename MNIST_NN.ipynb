{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense,Activation, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "59995      9       0       0       0       0       0       0       0       0   \n",
       "59996      1       0       0       0       0       0       0       0       0   \n",
       "59997      8       0       0       0       0       0       0       0       0   \n",
       "59998      8       0       0       0       0       0       0       0       0   \n",
       "59999      7       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "59995       0    ...            0         0         0         0         0   \n",
       "59996       0    ...           73         0         0         0         0   \n",
       "59997       0    ...          160       162       163       135        94   \n",
       "59998       0    ...            0         0         0         0         0   \n",
       "59999       0    ...            0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "59995         0         0         0         0         0  \n",
       "59996         0         0         0         0         0  \n",
       "59997         0         0         0         0         0  \n",
       "59998         0         0         0         0         0  \n",
       "59999         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv(\"d:/ML--perceptron/fashion_mnist_train.csv\")\n",
    "ds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 785)\n"
     ]
    }
   ],
   "source": [
    "data=ds.values[10000:30000]\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 784)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "#X = data[:,1:]\n",
    "X = data[:,1:]/255.0\n",
    "y=data[:,0]\n",
    "print (X.shape)\n",
    "print (y.shape)\n",
    "nb_classes=len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "6 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "6 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "Y = np_utils.to_categorical(y)\n",
    "for ix in range(10):\n",
    "    print (y[ix], Y[ix])\n",
    "##with sigmoid dont need this encoding but with softmax it's required.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 784) (16000, 10)\n"
     ]
    }
   ],
   "source": [
    "split = int(0.8*data.shape[0])\n",
    "X_train=X[:split]\n",
    "X_test=X[split:]\n",
    "y_train=Y[:split]\n",
    "y_test = Y[split:]\n",
    "print (X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output is bounded in 0 to 255 so we will use relu.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#softmax goes in hand in hand with categorical crossentropy..\n",
    "#backpropogation required when writing own loss function..\n",
    "#optimizer works inside loss fn, and controls how to come down the slope.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "16000/16000 [==============================] - 7s 460us/step - loss: 0.8082 - acc: 0.7081 - val_loss: 0.5627 - val_acc: 0.8025\n",
      "Epoch 2/20\n",
      "16000/16000 [==============================] - 7s 412us/step - loss: 0.5532 - acc: 0.7992 - val_loss: 0.4924 - val_acc: 0.8295\n",
      "Epoch 3/20\n",
      "16000/16000 [==============================] - 7s 411us/step - loss: 0.5029 - acc: 0.8152 - val_loss: 0.4573 - val_acc: 0.8432\n",
      "Epoch 4/20\n",
      "16000/16000 [==============================] - 6s 405us/step - loss: 0.4701 - acc: 0.8273 - val_loss: 0.4532 - val_acc: 0.8367\n",
      "Epoch 5/20\n",
      "16000/16000 [==============================] - 7s 414us/step - loss: 0.4433 - acc: 0.8371 - val_loss: 0.4309 - val_acc: 0.8495\n",
      "Epoch 6/20\n",
      "16000/16000 [==============================] - 7s 417us/step - loss: 0.4232 - acc: 0.8447 - val_loss: 0.4188 - val_acc: 0.8517\n",
      "Epoch 7/20\n",
      "16000/16000 [==============================] - 7s 418us/step - loss: 0.4072 - acc: 0.8517 - val_loss: 0.4268 - val_acc: 0.8502\n",
      "Epoch 8/20\n",
      "16000/16000 [==============================] - 7s 420us/step - loss: 0.3980 - acc: 0.8547 - val_loss: 0.4177 - val_acc: 0.8530\n",
      "Epoch 9/20\n",
      "16000/16000 [==============================] - 7s 414us/step - loss: 0.3870 - acc: 0.8590 - val_loss: 0.4197 - val_acc: 0.8472\n",
      "Epoch 10/20\n",
      "16000/16000 [==============================] - 7s 420us/step - loss: 0.3754 - acc: 0.8574 - val_loss: 0.3968 - val_acc: 0.8602\n",
      "Epoch 11/20\n",
      "16000/16000 [==============================] - 7s 415us/step - loss: 0.3648 - acc: 0.8664 - val_loss: 0.3963 - val_acc: 0.8557\n",
      "Epoch 12/20\n",
      "16000/16000 [==============================] - 7s 419us/step - loss: 0.3521 - acc: 0.8700 - val_loss: 0.3806 - val_acc: 0.8660\n",
      "Epoch 13/20\n",
      "16000/16000 [==============================] - 7s 418us/step - loss: 0.3524 - acc: 0.8691 - val_loss: 0.3772 - val_acc: 0.8710\n",
      "Epoch 14/20\n",
      "16000/16000 [==============================] - 7s 426us/step - loss: 0.3385 - acc: 0.8729 - val_loss: 0.3687 - val_acc: 0.8720\n",
      "Epoch 15/20\n",
      "16000/16000 [==============================] - 7s 434us/step - loss: 0.3294 - acc: 0.8749 - val_loss: 0.3735 - val_acc: 0.8737\n",
      "Epoch 16/20\n",
      "16000/16000 [==============================] - 7s 434us/step - loss: 0.3258 - acc: 0.8785 - val_loss: 0.3835 - val_acc: 0.8657\n",
      "Epoch 17/20\n",
      "16000/16000 [==============================] - 7s 468us/step - loss: 0.3209 - acc: 0.8800 - val_loss: 0.3739 - val_acc: 0.8737\n",
      "Epoch 18/20\n",
      "16000/16000 [==============================] - 7s 462us/step - loss: 0.3143 - acc: 0.8840 - val_loss: 0.3722 - val_acc: 0.8715\n",
      "Epoch 19/20\n",
      "16000/16000 [==============================] - 7s 454us/step - loss: 0.3028 - acc: 0.8860 - val_loss: 0.3786 - val_acc: 0.8715\n",
      "Epoch 20/20\n",
      "16000/16000 [==============================] - 7s 447us/step - loss: 0.2989 - acc: 0.8886 - val_loss: 0.3603 - val_acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x274ddbda2b0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, nb_epoch=20, batch_size=50, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight -> absolute updation and not relative updation hence normalization\n",
    "#is required.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x00000274FE1A6FD0>\n",
      "(784, 512)\n",
      "(512,)\n",
      "dense_7\n",
      "--------------------\n",
      "<keras.layers.core.Activation object at 0x00000274FE1A62B0>\n",
      "activation_7\n",
      "--------------------\n",
      "<keras.layers.core.Dropout object at 0x00000274FD377198>\n",
      "dropout_4\n",
      "--------------------\n",
      "<keras.layers.core.Dense object at 0x00000274FD5338D0>\n",
      "(512, 10)\n",
      "(10,)\n",
      "dense_8\n",
      "--------------------\n",
      "<keras.layers.core.Activation object at 0x00000274FD533EF0>\n",
      "activation_8\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "##to get value of weights for specific values..\n",
    "for layer in model.layers:\n",
    "    print (layer)\n",
    "    if len(layer.get_weights())>0:\n",
    "        print (layer.get_weights()[0].shape)\n",
    "        print (layer.get_weights()[1].shape)\n",
    "    print (layer.get_config()['name'])\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
